import feedparser
import urllib.parse
import trafilatura
import requests
from pypdf import PdfReader
from io import BytesIO

# Headers para simular um navegador real e evitar bloqueios
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

import googlenewsdecoder

def validar_e_ler_link(url_google):
    """
    FunÃ§Ã£o 'Porteiro': 
    1. Decodifica o link do Google News (evita erro 400).
    2. Verifica se o domÃ­nio Ã© GOVERNAMENTAL (.gov.br).
    """
    try:
        # Decodifica a URL 'suja' do Google (CBM...) para a URL real
        try:
            # Tenta decodificador V1 (chamada direta da funÃ§Ã£o)
            url_real_obj = googlenewsdecoder.new_decoderv1(url_google)
            url_real = url_real_obj.get("decoded_url")
            
            if not url_real:
                 print(f"      âš ï¸ Decoder V1 vazio. Tentando Fallback Bot...")
                 raise Exception("Decoder Falhou")

        except Exception as e_dec:
             print(f"      âš ï¸ Falha no Decoder: {e_dec}")
             # Tenta requests com User-Agent de Bot (Googlebot as vezes passa direto)
             try:
                headers_bot = {"User-Agent": "Googlebot/2.1 (+http://www.google.com/bot.html)"}
                r = requests.get(url_google, headers=headers_bot, timeout=5, allow_redirects=True)
                if r.status_code == 200 and "google.com" not in r.url:
                    url_real = r.url
                else:
                    url_real = url_google
             except:
                url_real = url_google

        url_real = url_real.lower()
        
        # --- REGRA DE OURO RELAXADA: ACEITAR MAIS FONTES ---
        # Aceita: .gov.br, .leg.br, transparencia, mas tambÃ©m .org e portais conhecidos de licitaÃ§Ã£o
        if ".gov.br" not in url_real and ".leg.br" not in url_real:
            print(f"      âš ï¸ ALERTA (NÃ£o Ã© .gov, mas vamos analisar): {url_real[:40]}...")
            # return None -> REMOVIDO PARA TESTE

        # --- REGRA DE PRATA: LISTA NEGRA DE NOTÃCIAS ---
        # Bloqueia portais de notÃ­cias conhecidos que poluem a busca
        bloqueados = ["globo.com", "terra.com.br", "uol.com.br", "folha", "estadao", "metropoles", "concurso", "jusbrasil"]
        if any(b in url_real for b in bloqueados):
            print(f"      âŒ REJEITADO (Portal de NotÃ­cia): {url_real[:40]}...")
            return None
            
        print(f"      âœ… APROVADO: {url_real[:50]}...")

        # Baixa o conteÃºdo da URL REAL
        resp = requests.get(url_real, headers=HEADERS, timeout=15, verify=False)
        
        # Tenta extrair texto de PDF
        if url_real.endswith(".pdf") or b"%PDF" in resp.content[:20]:
            try:
                pdf = BytesIO(resp.content)
                reader = PdfReader(pdf)
                text = ""
                for page in reader.pages[:4]: text += page.extract_text() + "\n"
                return f"[FONTE: {url_real}]\n\n[PDF]: {text[:6000]}"
            except:
                pass

        # Tenta extrair texto de Site HTML
        text = trafilatura.extract(resp.content)
        if text and len(text) > 200:
             return f"[FONTE: {url_real}]\n\n[SITE]: {text[:6000]}"
        
        return None

    except Exception as e:
        print(f"      âŒ Erro ao processar link: {e}")
        return None

async def buscar_licitacoes_gov():
    print(f"ğŸš€ Iniciando Varredura RIGOROSA (Apenas .gov.br)...")
    
    # Busca mais ampla para garantir resultados
    query = 'licitaÃ§Ã£o "aviso de licitaÃ§Ã£o" (medicamentos OR hospitalar)'
    
    # Codifica a busca para URL vÃ¡lida
    url = f"https://news.google.com/rss/search?q={urllib.parse.quote(query)}&hl=pt-BR&gl=BR&ceid=BR:pt-419"
    
    feed = feedparser.parse(url)
    print(f"ğŸ” Google trouxe {len(feed.entries)} links brutos. Filtrando...")
    
    licitacoes_validas = []
    
    for entry in feed.entries:
        titulo = entry.title.lower()
        
        # Filtro preliminar de tÃ­tulo (jÃ¡ descarta SP, RJ e Concursos Ã³bvios)
        termos_lixo = ["sÃ£o paulo", "rio de janeiro", "minas", "concurso", "polÃ­cia", "vaga", "futebol", "show", "crime"]
        if any(x in titulo for x in termos_lixo):
            continue

        # ValidaÃ§Ã£o profunda do link
        conteudo = validar_e_ler_link(entry.link)
        
        if conteudo:
            licitacoes_validas.append({
                "titulo": entry.title,
                "link": entry.link,
                "resumo": f"{entry.title}\n{conteudo}"
            })
        
        # Limita a 10 resultados vÃ¡lidos para agilidade
        if len(licitacoes_validas) >= 10: 
            break
            
    print(f"ğŸ“¦ Pacote fechado com {len(licitacoes_validas)} editais OFICIAIS.")
    return licitacoes_validas